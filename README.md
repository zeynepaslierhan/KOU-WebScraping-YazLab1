# .Net Core ile Web Scraping E-Ticaret

## Ä°Ã§erik

1. Proje TanÄ±tÄ±mÄ±
2. KullanÄ±lan AraÃ§larÄ±n AÃ§Ä±klamalarÄ±
3. Proje AlgoritmasÄ±

## GiriÅŸ

Trendyol, Hepsiburada, n11, Amazon, gibi e ticaret sitelerinden istenilen Ã¼rÃ¼ne ait bilgilerin yer aldÄ±ÄŸÄ± bir veritabanÄ± oluÅŸturulacak ve bu veritabanÄ±ndan istenilen bilgileri web sayfasÄ± Ã¼zerinde gÃ¶sterilecektir.

E-Ticaret sitelerine benzer yapÄ±ya sahiptir ama sadece bilgisayar kategorisinden oluÅŸturulmuÅŸtur.

E-ticaret sitesinin kontrolÃ¼ Admin tarafÄ±ndan saÄŸlanmaktadÄ±r. Bu adminin yetkileri sayesinde:

- Sadece Admin tarafÄ±ndan yapÄ±lan iÅŸlemler:
    - Bir notebook Ã¼rÃ¼nlerinin fiyatÄ±nÄ±n deÄŸiÅŸtirilmesi
    - Notebook Ã¼rÃ¼nÃ¼ne ait bir kaydÄ±n kaldÄ±rÄ±lmasÄ±
    - Yeni notebook Ã¼rÃ¼nlerinin eklenmesi
    - Notebook Ã¼rÃ¼nlerinin puanÄ±nda deÄŸiÅŸiklik yapÄ±lmasÄ±
- Web Scraping ile veri yÃ¶netme:
    - ÃœrÃ¼n bilgilerinin gÃ¼ncellenmesi

## ArayÃ¼z

Ana Sayfada veritabanÄ±nda yer alan tÃ¼m kayÄ±tlar lislenmiÅŸtir. Listelenirken her Ã¼rÃ¼nÃ¼n ismi sahip olduÄŸu tÃ¼m Ã¶zellikleri kapsÄ±yor ve ismine tÄ±klandÄ±ÄŸÄ±nda ilgili Ã¼rÃ¼nÃ¼n detaylÄ± bilgisine ulaÅŸÄ±lÄ±yor. Ä°sminin altÄ±nda Ã¼rÃ¼ne ait en dÃ¼ÅŸÃ¼k 3 fiyat sÄ±ralanmakta ve bu 3 fiyatÄ±n olduÄŸu e-ticaret sitesinin linki bulunmaktadÄ±r.

Layout kÄ±smÄ±nda herhangi bir Ã¼rÃ¼nle ilgili arama kÄ±smÄ± bulunuyor. Buradan Ã¼rÃ¼nÃ¼n ismi, modeli ya da bulunduÄŸu e-ticaret sitesine gÃ¶re arama yapÄ±labiliyor. Arama yanlÄ±ÅŸÄ± olduÄŸunda sistem dÃ¼zeltilmiÅŸ Ã¶neride bulunuyor.

Ana SayfanÄ±n sol tarafÄ±nda ise dinamik filtreleme kÄ±smÄ± bulunmakta. En dÃ¼ÅŸÃ¼k fiyattan en yÃ¼ksek fiyata, en yÃ¼ksek fiyattan en dÃ¼ÅŸÃ¼k fiyata ve en 
yÃ¼ksek puandan en dÃ¼ÅŸÃ¼k fiyata ÅŸeklinde sÄ±ralama iÅŸlemleri ise arama kÄ±smÄ±nÄ±n altÄ±nda mevcuttur. Laptop bilgilerinin yer aldÄ±ÄŸÄ± alanda fiyat bilgisi iÃ§in de aynÄ± durum geÃ§erlidir.

ArayÃ¼zâ€™Ã¼ tasarlarken W3school css templates kullandÄ±k. Ä°stediÄŸimiz sadeleÅŸtirilmeleri yaptÄ±ktan sonra ilave olarak ihtiyacÄ±mÄ±z olan Ã¶zellikleri baÅŸka Ã¼cretsiz ÅŸablonlardan saÄŸladÄ±k.

Sayfalar: 

1. Ana Sayfa: TÃ¼m verilerin listelendiÄŸi, filtrelenerek sÄ±ralandÄ±ÄŸÄ± sayfa.
2. Login: Sistemde kayÄ±tlÄ± adminin giriÅŸ yaptÄ±ÄŸÄ± sayfa.
3. Admin Paneli: Adminin verileri kontrol ettiÄŸi sayfa.

## Django yapÄ±sÄ±

### Django projesinin oluÅŸturulmasÄ±

1. Gerekli paketlerin yÃ¼klenmesi
    
    ```bash
    pip install django
    pip install djongo
    pip install pymongo
    ```
    
2. Projenin oluÅŸturulmasÄ±
    1. Proje Databaseâ€™e 2. gÃ¶rseldeki DATABASES deÄŸiÅŸkeni iÃ§erisindeki yapÄ± aracÄ±lÄ±ÄŸÄ±yla eriÅŸim saÄŸlar.
    
    ```python
    django-admin startproject projeismi
    python manage.py startapp appismi // oluÅŸturulan app aÅŸaÄŸÄ±daki gibi, settings.py iÃ§erisindeki installed_apps klasÃ¶rÃ¼ne yazÄ±lmalÄ±dÄ±r.
    ```
    
    ![Untitled](README%20md%2012bb0b63b45b4f7b9dfdfea4a5f15e33/Untitled.png)
    
    ![database connection.png](README%20md%2012bb0b63b45b4f7b9dfdfea4a5f15e33/database_connection.png)
    
3. Web sayfasÄ±nÄ±n URLâ€™leri tanÄ±mlanÄ±r.
    
    ![url_proje.png](README%20md%2012bb0b63b45b4f7b9dfdfea4a5f15e33/url_proje.png)
    
4. Html baÄŸlantÄ± iÅŸlemleri ve sayfaya yansÄ±tÄ±lmasÄ±
    1. TanÄ±mlanan urlâ€™ye html dosyalarÄ±nÄ±n baÄŸlanmasÄ± iÃ§in oluÅŸturduÄŸumuz app iÃ§indeki â€œviews.pyâ€ dosyasÄ±na eriÅŸilir ve request iÅŸlemleri oluÅŸturulur.
    2. HTML sayfalarÄ±nÄ±n database ile baÄŸlantÄ± kurmasÄ± iÃ§in gerekli baÄŸlantÄ±lar gÃ¶rseldeki gibi yapÄ±lÄ±r (MongoDB)
        
        ![views.png](README%20md%2012bb0b63b45b4f7b9dfdfea4a5f15e33/views.png)
        
5.  Databaseâ€™de kullanacaÄŸÄ±mÄ±z Table yapÄ±sÄ±, app iÃ§erisindeki [models.py](http://models.py) iÃ§erisinde oluÅŸturulur
    
    ![model.png](README%20md%2012bb0b63b45b4f7b9dfdfea4a5f15e33/model.png)
    
    ```python
    def __str__(self):
            return f"{self.name}, {self.marka}"
    ```
    
    def yapÄ±sÄ± admin panelindeki gÃ¶rÃ¼ntÃ¼lemede okuma kolaylÄ±ÄŸÄ± saÄŸlamak iÃ§in kiÅŸiselleÅŸtirilebilir. (gÃ¶rseldeki Ã¶rnek Ã¼rÃ¼nÃ¼n isim ve marka deÄŸerlerini 2 column ÅŸeklinde admin panelinde gÃ¶rÃ¼ntÃ¼ler. Admin Panel KÄ±sÄ±m: X)
    
6. OluÅŸturulan Table yapÄ±sÄ±nÄ±n ve diÄŸer deÄŸiÅŸikliklerin databaseâ€™e yansÄ±tÄ±lmasÄ±:
    1. migration oluÅŸturma
        
        ![makemigrations.png](README%20md%2012bb0b63b45b4f7b9dfdfea4a5f15e33/makemigrations.png)
        
        > â€œNot Implemented Error: Database objects do not implement truth value testing or bool().â€ hatasÄ± almamak iÃ§in: `pip install pymongo==3.12.3`
        > 
    2. migrationâ€™Ä± gÃ¶nderme
        
        ![migrate.png](README%20md%2012bb0b63b45b4f7b9dfdfea4a5f15e33/migrate.png)
        
    3. BunlarÄ± denetlemek ve admin sayfasÄ±na eriÅŸmek iÃ§in admin kullanÄ±cÄ±sÄ± oluÅŸturma (migration oluÅŸturmadan bu aÅŸamaya geÃ§meyiniz!!!)
        
        ![admincreatesuperuser.png](README%20md%2012bb0b63b45b4f7b9dfdfea4a5f15e33/admincreatesuperuser.png)
        
7. Projeye ekleyeceÄŸimiz HTML dosyalarÄ± okunurluk ve genel iÅŸleyiÅŸ kolaylÄ±ÄŸÄ± aÃ§Ä±sÄ±ndan proje iÃ§erisine aÃ§Ä±lan â€œtemplatesâ€ klasÃ¶rÃ¼ iÃ§erisindeki â€œappismiâ€ klasÃ¶rÃ¼ne yerleÅŸtirilir. Templates klasÃ¶rÃ¼nÃ¼n projeye tanÄ±tÄ±lmasÄ± ise aÅŸaÄŸÄ±daki gÃ¶rseldeki gibidir.
    
    ![templates.png](README%20md%2012bb0b63b45b4f7b9dfdfea4a5f15e33/templates.png)
    
8. HTML sayfalarÄ±na database Ã¼zerinden bilgi aktarabilmek iÃ§in app iÃ§erisinde bulunan â€œurls.pyâ€ iÃ§erisine gerekli baÄŸlantÄ±lar yapÄ±lÄ±r.
    
    ![url_app.png](README%20md%2012bb0b63b45b4f7b9dfdfea4a5f15e33/url_app.png)
    
9. Admin sayfasÄ±na baÄŸlantÄ± saÄŸlamak ve dÃ¼zenlemek iÃ§in app iÃ§erisindeki â€œadmin.pyâ€ iÃ§erisinde aÅŸaÄŸÄ±daki iÅŸlemler uygulanÄ±r. (GerektiÄŸi gibi kiÅŸiselleÅŸtirilebilir.)
    
    ![adminpy.png](README%20md%2012bb0b63b45b4f7b9dfdfea4a5f15e33/adminpy.png)
    
10. Projenin Ã¶rnek gÃ¶rÃ¼ntÃ¼leri:
    
    ![homepage.png](README%20md%2012bb0b63b45b4f7b9dfdfea4a5f15e33/homepage.png)
    
    ![productpage.png](README%20md%2012bb0b63b45b4f7b9dfdfea4a5f15e33/productpage.png)
    
    ![adminpage.png](README%20md%2012bb0b63b45b4f7b9dfdfea4a5f15e33/adminpage.png)
    
    ![adminindex.png](README%20md%2012bb0b63b45b4f7b9dfdfea4a5f15e33/adminindex.png)
    
    ![adminlisting.png](README%20md%2012bb0b63b45b4f7b9dfdfea4a5f15e33/adminlisting.png)
    
11. Admin sayfasÄ±nÄ±n Ã¶zelleÅŸtirilebilmesi (Web scraping iÃ§in buton eklenmesi vb.) iÃ§in hazÄ±r bir app kullandÄ±k.
    
    ![adminbutton.png](README%20md%2012bb0b63b45b4f7b9dfdfea4a5f15e33/adminbutton.png)
    

## Web Scraping

**Web Scraping yaparken dikkat edilmesi gerekenler:,**

1. Ãœzerinde Ã§alÄ±ÅŸÄ±lan sitenin URL geÃ§erlilik kontrolÃ¼
    
    ```python
    import validators
    
    valid=validators.url('https://github.com/')
    
    if valid==True:
        print("Url geÃ§erli")
    else:
        print("Url geÃ§ersiz")
    ```
    
2. Request atÄ±lan geÃ§erli urlnin response deÄŸerinin 200 olup olmamasÄ±
    
    ```python
    response = requests.get(base_url.format(i), headers=headers)
    print(response)
    ```
    
3. Sitede istenilen verinin olup olmamasÄ±
    1. BeautifulSoap
        1. if ile None olup olmama
        2. try except yapÄ±sÄ±
    2. Selenium
        1. try catch ile hata mesajlarÄ±nÄ± dÃ¶ndÃ¼r. Bunun iÃ§in ilgili kÃ¼tÃ¼phaneleri ekle.
        
        ```python
        from selenium.common.exceptions import NoSuchElementException
        try:
        	veri = browser.find_element("css selector","#productDetailsCarousel > div.owl-stage-outer > div > div.owl-item.active > a > picture > img")
        except NoSuchElementException:
        	print("Exception Handled")
        	continue
        ```
        

---

**Veri Ã§ekerken selenium ile beutifulSoap karÄ±ÅŸÄ±k kullandÄ±k. BeutifulSoapâ€™da veri Ã§ekememe problemi seleniuma gÃ¶re daha Ã§ok oldu.**

### Web Scraping KullanÄ±lan KÃ¼tÃ¼phaneler

```python
#BeautifulSoup
from bs4 import BeautifulSoup
import requests

#Selenium
from selenium import webdriver
from selenium.webdriver.common.keys import Keys
from selenium.webdriver.common.by import By
from selenium.common.exceptions import NoSuchElementException

#Kontrol
import validators
```

### Selenium KÃ¼tÃ¼phanesi

1. Google Ã¼zerinden arama yaptÄ±rma
    
    ```python
    browser = webdriver.Chrome(driver_path)
    browser.get("https://www.google.com/")
    Veri_girisi = browser.find_element("css selector",".gLFyf.gsfi")
    Veri_girisi.send_keys("AranÄ±lacak veri")
    Veri_girisi.send_keys(Keys.ENTER)
    ```
    
2. Ä°lgili sayfaya yÃ¶nlendirme
    
    ```python
    # xpath gibi aramalar da yapÄ±labilir
    tikla = browser.find_element("css selector","ilgili sayfanÄ±n linkinin olduÄŸu yerin selector kopyasÄ±")
    tikla.click()
    ```
    
3. Fotograf indirme *(Projenin gÃ¼ncel halinde bu Ã¶zelliÄŸe gerek kalmadÄ±, isteÄŸe baÄŸlÄ± kullanÄ±labilir)*
    
    ```python
    img_url = browser.find_element("XXXXXXX").get_attribute("src")
    browser.get(img_url)
    img_loc = "C:/Users/zerha/Downloads/xxxx.png"
    browser.save_screenshot(img_loc)
    ```
    
4. Veri Ã‡ekme
    
    ```python
    product_price = browser.find_element("css selector","#pdp-main > div.pdp-block2.pdpGeneralWidth > div.pdp-details > div.addtocart-component > div > div.AddToCart-AddToCartAction > div > div.pdp-amount.prc-last-2 > div > div > span")
    product_priceText = product_price.get_attribute("innerHTML")
    ```
    

### BeautifulSoap KÃ¼tÃ¼phanesi

1. Veri Ã§ekme
    
    ```python
    response = requests.get(base_url.format(i), headers=headers)
    soup = BeautifulSoup(response.content, 'html.parser')
    results = soup.find_all('li',{'class': 'productListContent-zAP0Y5msy8OHn5z7T_K_'})
    ```
    

## VeritabanÄ±

Web sitelerinden veri Ã§ekerken ilk Ã¶nce request ile web sitelerine giriÅŸ yaptÄ±k. Daha sonrasÄ±nda aldÄ±ÄŸÄ±mÄ±z response deÄŸerler 200â€™Ã¼ gÃ¶sterdiÄŸini teyit edince response iÃ§erisindeki html bilgileri kullanarak request attÄ±ÄŸÄ±mÄ±z site iÃ§indeki verileri Ã§ektik. Ã‡ektiÄŸimiz verileri direkt olarak mongoDbâ€™ye kaydettik.

KullandÄ±ÄŸÄ±mÄ±z varlÄ±klarÄ±n(entitys) temel Ã¶zellikleri: 

- Bilgisayar:
    - FotoÄŸrafÄ±
    - Marka Model
    - AdÄ±
    - Model No Ä°ÅŸletim sistemi
    - Ä°ÅŸlemci tipi
    - Ä°ÅŸlemci nesli
    - Ram Disk boyutu
    - Disk tÃ¼rÃ¼
    - Ekran boyutu
    - PuanÄ±
    - Fiyat
    - Bu bilgilerin alÄ±ndÄ±ÄŸÄ± site/siteler
- User(Admin):
    - KullanÄ±cÄ± adÄ±
    - Åžifresi

Scraping ile Ã§ekilen bilgiler dÃ¼zenli olarak veritabanÄ±nda ve sitede gÃ¼ncellenmektedir. 

Ã–nceden kayÄ±tlÄ± olan bir verinin tekrardan kaydÄ±nÄ±n Ã¶nlenmesi iÃ§in Duplicate kontrolÃ¼ yapÄ±lmaktadÄ±r. AynÄ± zamanda Near Duplicate kontrolÃ¼ ile aynÄ± Ã¼rÃ¼n bilgilerinin farklÄ± isimlendirmelere tekrarlanmamasÄ± saÄŸlanÄ±r. 

### Neden MongoDB KullandÄ±k?

Semi-structured, json tipinde veriler varsa ve bu verilerin herhangi bir yerinde sorgulama, groupby gibi iÅŸlemler gerekiyorsa DokÃ¼man tabanlÄ± (Document- Oriented) NoSQL veritabanlarÄ± seÃ§ilir. MongoDB dokÃ¼man tabanlÄ± NoSql veritabanlarÄ±ndan biridir. Peki Ã¶zellikle bu tÃ¼r veritabanlarÄ±ndan MongoDB veritabanÄ±nÄ± seÃ§tik?

Ã‡Ã¼nkÃ¼ MongoDBâ€™nin Ã§okÃ§a kendine ait nasÄ±l kullanÄ±lacaÄŸÄ±nÄ± anlatan kaynaklara sahip. DiÄŸer DokÃ¼man tabanlÄ± NoSQL veritabanlarÄ±na gÃ¶re daha Ã§ok kullanÄ±lÄ±yor.Bu da proje geliÅŸtirirken daha kolay ilerlememizi saÄŸladÄ±.

![Screenshot 2022-10-09 161909.png](README%20md%2012bb0b63b45b4f7b9dfdfea4a5f15e33/Screenshot_2022-10-09_161909.png)

MongoDB, verileri kaydettiÄŸi dokumanlarÄ± JSON benzeri Binary JSON (BSN) formatÄ±nda saklar. MongoDBâ€™de yaptÄ±ÄŸÄ±mÄ±z iÅŸlemlerin iliÅŸkisel veritabanÄ±ndaki karÅŸÄ±lÄ±klarÄ±:

---

### MongoDb VeritabanÄ± OluÅŸturma

MongoDb de yapÄ±lan iÅŸlemler:

1. Yeni bir Cluster oluÅŸturuldu. Ä°smi: "Cluster-WebScraping"
2. Cluster-WebScraping iÃ§in veritabanÄ± eriÅŸim izni verilen iki kullanÄ±cÄ± oluÅŸturuldu.
    - isim: zeyneperhan ÅŸifre: 20012022
    - isim: hazarkoc ÅŸifre:20012022
3. Cluster-WebScraping'e IP Ã¼zerinden otomatik baÄŸlanmak iÃ§in Ip adresi eklendi
    
    > **Not: *Colab Notebook*** Ã¼zerinden denemeler yaptÄ±ÄŸÄ±mÄ±z iÃ§in IP hatasÄ± almamak adÄ±na â€œAllow Acces From Anywhereâ€ Ã¶zelliÄŸini seÃ§tik.
    > 
4. Cluster iÃ§erisine yeni veritabanÄ± eklenip koleksiyon oluÅŸturuldu.

### MongoDb BaÄŸlantÄ±sÄ±nÄ± OluÅŸturma

```python
# MongoDb iÅŸlemleri iÃ§in gerekli kÃ¼tÃ¼phaneler eklendi
import pymongo
```

Cluster-WebScraping Urlâ€™sini elde etmek iÃ§in:

1. MongoDb Atlas veya MongoDb Compass'a gÃ¶re seÃ§im yapÄ±lÄ±r.
    - MongoDb Atlas'Ä± seÃ§tiÄŸimiz iÃ§in MongoDB Drivers kÄ±smÄ± seÃ§ilir.
2. Driver ve versiyonu seÃ§ilir.
    - Driver: Pyhton Versiyon: 3.4 ve sonrasÄ±
        
        > **NOT:** Burada verdiÄŸi linki direkt kopyalamamak gerekiyor! Direkt olarak verdiÄŸi link iÃ§erisinde admin veritabanÄ± baÄŸlantÄ±sÄ± iÃ§eriyor ama bu Mongo Atlas Ã¼zerinden gÃ¶rÃ¼nmÃ¼yor. Bu yÃ¼zden Compas kullanmasak bile urlâ€™yi istediÄŸimiz ÅŸekilde ayarlamak iÃ§in Compasâ€™Ä± kullandÄ±k.
        > 

```python
# Cluster-WebScraping iÃ§in baÄŸlantÄ± saÄŸlandÄ± (Compass yardÄ±mÄ± ile). (username: zeyneperhan password: 20012022)
myclient = pymongo.MongoClient("mongodb://zeynep:20012022@ac-akv12vk-shard-00-00.6erqfem.mongodb.net:27017,ac-akv12vk-shard-00-01.6erqfem.mongodb.net:27017,ac-akv12vk-shard-00-02.6erqfem.mongodb.net:27017/?ssl=true&replicaSet=atlas-8ffx15-shard-0&retryWrites=true&w=majority") 

# KullanacaÄŸÄ±mÄ±z veritabanÄ± iÃ§in eriÅŸim saÄŸladÄ±k.
mydb = myclient["Bilgisayar"]

# Bilgisayar VeritabanÄ±ndaki Amazon koleksiyonuna eriÅŸim saÄŸladÄ±k
mycollectionAmazon= mydb["Amazon"]
```

### MongoDb CRUD Ä°ÅŸlemleri

1. **CREATE**
    
    ```python
    mycollection.insert_one(XXXX)
    ```
    
2. **READ**
    1. Koleksiyon Ä°Ã§erisindeki Verileri okuma
    
    ```python
    # mycollection iÃ§erisindeki verileri teker teker alÄ±p ilgili Ã¶zelliÄŸi yazdÄ±rÄ±r.
    for product in mycollection.find({}):
      print(product['Name'])
    ```
    
    b. Koleksiyon iÃ§erisindeki verinin **gÃ¶mÃ¼lÃ¼ dokÃ¼mantasyon** bilgilerini okuma:
    
    ```python
    for product in mycollection.find({}):
      print("----------------")
      print(product['Name'])
      print("\n")
    
      hepsiburada = product['HepsiBurada']
    
      print("HepsiBurada Bilgileri:")
      print(hepsiburada['URL'])
      print(hepsiburada['Price'])
    
      print("\n")
      trendyol = product['Trendyol']
    
      print("Trendyol Bilgileri:")
      print(trendyol['URL'])
      print(trendyol['Price'])
      print("----------------")
    ```
    
    ***Ã‡Ä±ktÄ±sÄ±:*** 
    
    ![MongoDb Verilerine EriÅŸme 1.png](README%20md%2012bb0b63b45b4f7b9dfdfea4a5f15e33/MongoDb_Verilerine_Erime_1.png)
    
3. **UPDATE**
    1. Verinin iÃ§erisinde **gÃ¶mÃ¼lÃ¼ dokÃ¼mantasyonu** gÃ¼ncelleme:
    
    ```python
    #Name bilgisi product['Name'] olan verinin Trendyol Objesinin iÃ§erisindeki URL bilgisini gÃ¼nceller
    mycollection.update_one({ "Name" : product['Name'] },{ "$set": {"Trendyol.URL": "yeni bilgi"}})
    ```
    
4. **DELETE**

### MongoDb Sorgulama Ä°ÅŸlemleri

1. ***Filtreleme***
    
    **ObjectId:**
    
    ```python
    # ObjectId sorgulamasÄ± yapmak iÅŸÃ§in gerekli kÃ¼tÃ¼phane
    from bson.objectid import ObjectId
    product = mycollection.find_one({"_id": ObjectId('Aranan verinin idsi')})
    
    # Ä°lgili verinin ObjectId deÄŸerini Ã§ekmek iÃ§in:
    id = product['_id']
    ```
    

## WebScraping ve MongoDB AlgoritmasÄ±

> **NOT:** Google CAPTCHAâ€™dan kurtulmak User Agentâ€™Ä± sÃ¼rekli deÄŸiÅŸtirmek veya insan davranÄ±ÅŸlarÄ±na daha uygun olacak ÅŸekilde time.sleep() komutu kullanmak faydalÄ± olabiliyor.
> 

### BaÅŸka KullanÄ±m ÅŸekilleri

AslÄ±nda bu algoritmayÄ± ÅŸu ÅŸekilde uyarlayabilirsiniz:

1. Åžimdiki halinde olduÄŸu bir belli bir eticaret sitesinin bilgisayar sayfalarÄ±nÄ± baz alÄ±p diÄŸer sitelerden fiyat bilgileri Ã§ekerek Ã§alÄ±ÅŸma.
2. Elinizde bulunan bilgisayar isimlerini(bu isimler model,marka,seri no, ram gibi detaylÄ± bilgiler bulundurmalÄ±) diÄŸer sitelerde aratarak veri ekleme.
3. SÄ±rayla sitelerin hepsinden model ismi alarak.
    
    <aside>
    ðŸš¨ NOT: MongoDb iÃ§erisinde verilerin duplicate olmasÄ±nÄ± engellemek adÄ±na:
    
    </aside>
    
    1. Ã–renÄŸin ilk olarak hepsiburadadan Bilgisayar isimleri, ilgili bilgisayarÄ±n fotoÄŸrafÄ± ve detaylÄ± biligsini Ã§ekip elimizde bulunan **7 web sitesi**(hepsiburada,amazon,trendyol,n11,Ã§iÃ§eksepeti,vatan,teknosa) iÃ§in arama yaptÄ±ralÄ±m.
    2. bittikten sonra amazondan bilgisayar isimleri, ilgili bilgisayarÄ±n fotoÄŸrafÄ± ve detaylÄ± biligsini Ã§ekip elimizde bulunan **6 web** sitesi(amazon,trendyol,n11,Ã§iÃ§eksepeti,vatan,teknosa) iÃ§in arama yaptÄ±ralÄ±m.
        1. Bu aÅŸamada mongodb iÃ§erisinde kayÄ±tlÄ± verilerde amazon.mevcut bilgisi true olanla amazondan Ã§ekilen bilgileri karÅŸÄ±laÅŸtÄ±rÄ±lmalÄ±. Ã§akÄ±ÅŸma olursa bu veri atlanÄ±p diÄŸer veriye geÃ§ilmeli.
    3. gibi gibi bu ÅŸekilde azaltÄ±larak devam ettirilebilir.

```python
def hepsiBuradaTam():

    mycollection.delete_many({})
    headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:94.0) Gecko/20100101 Firefox/94.0'}

    # Verileri Ã§ekeceÄŸimiz sitenin ana url'si
    base_url = 'https://www.hepsiburada.com/laptop-notebook-dizustu-bilgisayarlar-c-98?sayfa={0}'

    #veriyi tutan dict
    item = {}
    j=0
    for i in range(3,4):
        
        print('Processing {0}...'.format(base_url.format(i)))
        print("-------------")  
        time.sleep(0.50)  

        valid=validators.url(base_url.format(i))
                
        if valid==True:
            print("Valid url")
        else:
            print("Invalid url")
            print(base_url.format(i))
            continue
        
        response = requests.get(base_url.format(i), headers=headers)
        print(response)
        soup = BeautifulSoup(response.content, 'html.parser')
        results = soup.find_all('li',{'class': 'productListContent-zAP0Y5msy8OHn5z7T_K_'})
        
        for result in results:
            product_name = result.h3.text
            item["index"] = j
            j=j+1
            try:
                product_url = 'https://www.hepsiburada.com'+result.a.get("href")
                valid=validators.url(product_url)
                if valid==True:
                    
                    product_response = requests.get(product_url, headers=headers)
                    product_soup = BeautifulSoup(product_response.content, 'html.parser')
                    product_details = product_soup.find_all("table",{"class":"data-list tech-spec"})
                    detail={}
                    browser = webdriver.Chrome(driver_path)
                    time.sleep(0.50)
                    browser.get(product_url)
                    try:
                        Marka = browser.find_element("css selector","body > div.wrapper > main > div.product-detail-module > section.detail-main > div.container.contain-lg-4.contain-md-4.contain-sm-1.fluid > div > div.productDetailRight.col.lg-2.md-2.sm-1.grid-demo-fluid > div.product-information.col.lg-5.sm-1 > span > a").get_attribute("innerHTML")
                        detail["Marka"]= Marka
                    except NoSuchElementException:
                        print("Exception Handled")
                        continue
                    for details in product_details:

                        informations = details.find_all("tr")

                        for info in informations:

                            try:               
                                label = info.find("th").text
                                label=label.replace(" ", "")
                                value = info.find("span").text
                                detail[label]=value
                                
                            except AttributeError:
                                continue
                    item["Details"]=detail
                    try:
                        time.sleep(0.50)
                        img_url = browser.find_element("css selector","#productDetailsCarousel > div.owl-stage-outer > div > div.owl-item.active > a > picture > img").get_attribute("src")
                        item["Img"]= img_url
                    except NoSuchElementException:
                        print("Exception Handled")
                        continue
                    time.sleep(0.50)
                    browser.close()
                else:
                    print("Invalid url")
                    print(product_url)
                    continue    

                
            except AttributeError:
                continue

            item["Name"] = product_name

            mycollection.insert_one(item)
            item.clear()
```

```python
def cicekSepetiExtra(product):
    
    mycollection.update_one({ "Name" : product['Name'] },{ "$set": {"cicekSepetiExtra.Mevcut": False}})
    name = product['Name']
    time.sleep(0.50)
    browser = webdriver.Chrome(driver_path)
    browser.get("https://www.google.com/")
    time.sleep(0.50)

    cicekSepetiExtra_veri_girisi = browser.find_element("css selector",".gLFyf.gsfi")
    time.sleep(0.50)
    cicekSepetiExtra_veri_girisi.send_keys(name+" "+" site:ciceksepeti.com")
    time.sleep(0.50)
    cicekSepetiExtra_veri_girisi.send_keys(Keys.ENTER)
    time.sleep(0.50)
    try:
        cicekSepetiExtra_tikla = browser.find_element("css selector","#rso > div:nth-child(1) > div > div > div.Z26q7c.UK95Uc.jGGQ5e.VGXe8 > div > a")
        time.sleep(0.50)
        cicekSepetiExtra_tikla.click()
        product_url = browser.current_url

        if browser.find_element("css selector", "#productDetailSend > div > div > div:nth-child(2) > div.product__main-info-right.js-set-date-base-campaing-class > div.product__not-available.js-product-not-available.js-no-stock"):
            print("Stok bitmiÅŸ")
        else:
            product_price = browser.find_element("css selector","#productDetailSend > div > div > div:nth-child(2) > div.product__main-info-right.js-set-date-base-campaing-class > div:nth-child(2) > div > div.product__info-wrapper--right > div.product__info__price.js-default-price > div.product__info__new-price.js-price-container > div.product__info__new-price__integer.js-price-integer")
            product_priceText = product_price.get_attribute("innerHTML")
            
            
            if product_price is not None:
                mycollection.update_one({ "Name" : product['Name'] },{ "$set": {"cicekSepetiExtra.Price": product_priceText}})
                mycollection.update_one({ "Name" : product['Name'] },{ "$set": {"cicekSepetiExtra.URL": product_url}})
                mycollection.update_one({ "Name" : product['Name'] },{ "$set": {"cicekSepetiExtra.Mevcut": True}})
           
            try:
                product_rating = browser.find_element("css selector","#productDetailSend > div > div > div:nth-child(2) > div.product__main-info-right.js-set-date-base-campaing-class.has-date-base-discount > div:nth-child(2) > div > div.product__info-wrapper--right > div.product__header-summary.js-product-header-summary > div > div > p")
                product_ratingText = product_rating.get_attribute("innerHTML")
                mycollection.update_one({ "Name" : product['Name'] },{ "$set": {"cicekSepetiExtra.Rating": product_ratingText}})
                
            except NoSuchElementException:
                print("Exception Handled")
    except NoSuchElementException:
        print("Exception Handled")
    time.sleep(0.50)
    browser.close()
```

## KaynakÃ§a

1. BTK AKADEMÄ°: Talha KÄ±lÄ±Ã§
    
    [NoSQL - DokÃ¼man VeritabanlarÄ±](https://www.btkakademi.gov.tr/portal/course/nosql-dokueman-veritabanlari-21625)
    
2. Slider 
    
    [How to Create a Range Slider Using HTML & CSS?](https://uxplanet.org/how-to-create-a-range-slider-using-html-css-6112fe9346e4)
    
3. W3Schools Template
    
    [W3Schools online HTML editor](https://www.w3schools.com/w3css/tryit.asp?filename=tryw3css_templates_clothing_store&stacked=h)
    
4. MongoDB Crud & Connection
    
    [ASP.NET Core with MongoDB || Complete CRUD || MongoDB Compass || NoSQL || .NET 5.0](https://www.youtube.com/watch?v=dsvL22_w88I)
    
5. Checkbox 
    
    [How To Create a Custom Checkbox and Radio Buttons](https://www.w3schools.com/howto/howto_css_custom_checkbox.asp)
    
    [Implementing Checkbox Product Filters ASP.NET MVC - How Can I Pass Data in Collection through URL?](https://stackoverflow.com/questions/42283295/implementing-checkbox-product-filters-asp-net-mvc-how-can-i-pass-data-in-colle)
    
    [Checkbox Filter asp.net mvc| Applying Filters using Checkbox on Shop Page in ASP.Net MVC- Session 21](https://www.youtube.com/watch?v=I8ZZsXEeLxs)
    
6. Pyton json formatÄ±nda yazdÄ±rma
    
    [Pandas to_json: How to export DataFrame to JSON File](https://appdividend.com/2022/03/15/pandas-to_json/#:~:text=To%20convert%20the%20object%20to,use%20the%20to_json()%20function)
    
7. Pyhton with MongoDb
    
    [Python MongoDB](https://www.w3schools.com/python/python_mongodb_getstarted.asp)
    
8. Selenium ile web scraping
    
    [Web Scraping with Selenium in Pythonâ€Š-â€ŠAmazon Search Result(Part 1)](https://medium.com/@jb.ranchana/web-scraping-with-selenium-in-python-amazon-search-result-part-1-f09c88090932)
    
9. MongoDb dizi ve gÃ¶mÃ¼lÃ¼ dokÃ¼manlar ile Ã§alÄ±ÅŸmak
    
    [https://www.mongodb.com/docs/manual/core/document/](https://www.mongodb.com/docs/manual/core/document/)
    
10. MongoDb gÃ¶mÃ¼lÃ¼ dokÃ¼man gÃ¼ncellemek iÃ§in
    
    [$inc](https://www.mongodb.com/docs/v4.2/reference/operator/update/inc/?_ga=2.133247691.497944246.1666347531-498109847.1665859348)
    
11. Selenium hata dÃ¶ndÃ¼rme
    
    [How To Handle Errors And Exceptions In Selenium Python | LambdaTest](https://www.lambdatest.com/blog/handling-errors-and-exceptions-in-selenium-python/)
    
12. Filtreleme iÅŸlemleri
    
    [Django E-commerce Product Filter Prototype](https://www.youtube.com/watch?v=uDw7ArEVYSY)
    
    [Django Filtering System Using Django-Filter | Django Filtering Tutorial](https://www.youtube.com/watch?v=TTeNn3kNWD8)
    
13. Admin Paneline Buton Eklenmesi

[django-admin-extra-buttons](https://pypi.org/project/django-admin-extra-buttons/)