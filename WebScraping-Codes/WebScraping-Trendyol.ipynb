{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyOEWExVcIzgtp8LszZYQNWf"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Giriş"],"metadata":{"id":"2b7kRrp-qWXh"}},{"cell_type":"markdown","source":["### Veritabanı Oluşturma"],"metadata":{"id":"ioO4pNXQ7ztz"}},{"cell_type":"markdown","source":["MongoDb de yapılan işlemler:\n","\n","1. Yeni bir Cluster oluşturuldu. İsmi: \"Cluster-WebScraping\"\n","2. Cluster-WebScraping için veritabanı erişim izni verilen iki kullanıcı oluşturuldu.\n","  \n","  * isim: zeyneperhan şifre: 20012022\n","  * isim: hazarkoc şifre:20012022 \n","\n","3. Cluster-WebScraping'e IP üzerinden otomatik bağlanmak için Ip adresi eklendi\n","\n","4. Cluster içerisine yeni veritabanı eklenip koleksiyon oluşturuldu."],"metadata":{"id":"m9m4-nCL5uwe"}},{"cell_type":"markdown","source":["### Pyhton ile Veritabanına Bağlanma"],"metadata":{"id":"BuAFvVgd8HB6"}},{"cell_type":"code","source":["# MongoDb işlemleri için gerekli kütüphaneler eklendi\n","import pymongo "],"metadata":{"id":"IsyqFcsB8ty1"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Cluster-WebScraping'e bağlanmak için :\n","\n","1. MongoDb Atlas veya MongoDb Compass'a göre seçim yapılır.\n","  \n","  * MongoDb Atlas'ı seçtiğimiz için MongoDB Drivers kısmı seçilir.\n","\n","2. Driver ve versiyonu seçilir.\n","  \n","  * Driver: Pyhton Versiyon: 3.4 ve sonrası\n","\n","  Burada verdiği linki direkt kopyalamamak gerekiyor!!! "],"metadata":{"id":"k9BfM5XU8vCX"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"fRIs4oX6vYtu"},"outputs":[],"source":["# Cluster-WebScraping için bağlantı sağlandı. (username: zeyneperhan password: 20012022)\n","myclient = pymongo.MongoClient(\"mongodb://zeynep:20012022@ac-akv12vk-shard-00-00.6erqfem.mongodb.net:27017,ac-akv12vk-shard-00-01.6erqfem.mongodb.net:27017,ac-akv12vk-shard-00-02.6erqfem.mongodb.net:27017/?ssl=true&replicaSet=atlas-8ffx15-shard-0&retryWrites=true&w=majority\") \n","\n","# Kullanacağımız veritabanı için erişim sağladık.\n","mydb = myclient[\"Bilgisayar\"]\n","\n","# Bilgisayar Veritabanındaki Amazon koleksiyonuna erişim sağladık\n","mycollectionAmazon= mydb[\"Amazon\"]"]},{"cell_type":"markdown","source":["# BeatifulSoup ile Trendyol Web Scraping"],"metadata":{"id":"Y_fZdUc0omFu"}},{"cell_type":"code","execution_count":19,"metadata":{"id":"q4Zk1RD5-FyT","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1666041829256,"user_tz":-180,"elapsed":230300,"user":{"displayName":"Zeynep Aslı Erhan","userId":"03313672524286903446"}},"outputId":"5844a46d-422f-479e-eb1c-5a33ebb4545b"},"outputs":[{"output_type":"stream","name":"stdout","text":["-------------\n","Processing https://www.trendyol.com/laptop-x-c103108?pi=1...\n","-------------\n","<Response [200]>\n","<Response [200]>\n","None\n","<Response [200]>\n","None\n","<Response [200]>\n","None\n","<Response [200]>\n","None\n","<Response [200]>\n","None\n","-------------\n","Processing https://www.trendyol.com/laptop-x-c103108?pi=2...\n","-------------\n","<Response [200]>\n","<Response [200]>\n","None\n","<Response [200]>\n","None\n","<Response [200]>\n","None\n","<Response [200]>\n","None\n","-------------\n","Processing https://www.trendyol.com/laptop-x-c103108?pi=3...\n","-------------\n","<Response [200]>\n","<Response [200]>\n","None\n","<Response [200]>\n","None\n","<Response [200]>\n","None\n","<Response [200]>\n","None\n","<Response [200]>\n","None\n","<Response [200]>\n","None\n","<Response [200]>\n","None\n","<Response [200]>\n","None\n","<Response [200]>\n","None\n","<Response [200]>\n","None\n","<Response [200]>\n","None\n","<Response [200]>\n","None\n","<Response [200]>\n","None\n","<Response [200]>\n","None\n","<Response [200]>\n","None\n","<Response [200]>\n","None\n","<Response [200]>\n","None\n"]}],"source":["import requests\n","from bs4 import BeautifulSoup\n","import pandas as pd\n","from time import sleep\n","\n","# Web Scraping yapılırken ilgili koleksiyona erişiliyor.\n","mycollectionTrendyol= mydb[\"Trendyol\"]\n","\n","# Web scraping ile veri aktarmadan önce koleksiyon içeriğini tamamen siliyoruz.\n","mycollectionTrendyol.delete_many({}) \n","\n","headers = {\n","    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:94.0) Gecko/20100101 Firefox/94.0'}\n","\n","# Verileri çekeceğimiz sitenin ana url'si\n","base_url = 'https://www.trendyol.com/laptop-x-c103108?pi={0}'\n","\n","#veriyi tutan dict\n","item = {}\n","\n","for i in range(1, 4):\n","    \n","    print(\"-------------\")\n","    print('Processing {0}...'.format(base_url.format(i)))\n","    print(\"-------------\")    \n","\n","    # İstenilen sayfanın verileri alınıyor:\n","    response = requests.get(base_url.format(i), headers=headers)\n","    # Veri alımı başarılıysa response 200 olarak görülmeli 503 ise request işlemi hatalıdır\n","    print(response)\n","\n","    # BeautifulSoup ile verilerin içeriğini alıp html.parser ile parçalayıyor. soup içerisinde tutuyor\n","    soup = BeautifulSoup(response.content, 'html.parser')\n","\n","    # Olduğumuz sayfadaki tüm ürünlerin bilgisi results içerisine aktarılır:\n","    results = soup.find_all('div',{'class': 'p-card-wrppr with-campaign-view'})\n","\n","\n","    # Results içerisindeki ürün kadar bu for döngüsü döner.\n","    for result in results:\n","\n","        if result.find(\"span\",{\"class\":\"prdct-desc-cntnr-ttl\"}) is not None:\n","          brand = result.find(\"span\",{\"class\":\"prdct-desc-cntnr-ttl\"}).text\n","        else:\n","          break\n","        \n","        if result.find(\"span\",{\"class\":\"prdct-desc-cntnr-name hasRatings\"}) is not None:\n","          product_name = result.find(\"span\",{\"class\":\"prdct-desc-cntnr-name hasRatings\"}).text\n","        else:\n","          break\n","        \n","        item[\"product_name\"] = brand+\" \"+product_name\n","\n","\n","        try:\n","            product_url = \"https://www.trendyol.com\"+result.a.get(\"href\")\n","            item[\"product_url\"]= product_url\n","\n","            # Ürün hakkında detaylı bilgi edinmek için:\n","\n","            product_response = requests.get(product_url, headers=headers)\n","            print(product_response)\n","            \n","            product_soup = BeautifulSoup(product_response.content, 'html.parser')\n","\n","\n","            # ------- Fiyat -------\n","\n","            if product_soup.find(\"span\",{\"class\":\"prc-dsc\"}) is not None:\n","              product_price = product_soup.find(\"span\",{\"class\":\"prc-dsc\"}).text\n","\n","            else:\n","              product_price= None\n","\n","            item[\"price\"]=product_price\n","\n","            print(product_soup.find(\"div\",{\"class\":\"pr-rnr-sm-p\"}))\n","\n","            if product_soup.find(\"span\",{\"class\":\"tltp-avg-cnt\"}) is not None:\n","              rating =product_soup.find(\"span\",{\"class\":\"tltp-avg-cnt\"}).text\n","            else:\n","              rating = None\n","\n","            item[\"rating\"]=rating\n","\n","            # ------- Detaylar -------\n","\n","            product_details = product_soup.find_all(\"ul\",{\"class\":\"detail-attr-container\"})\n","\n","            for details in product_details:\n","              informations = details.find_all(\"li\",{\"class\":\"detail-attr-item\"})\n","\n","              for info in informations:\n","\n","                try:               \n","                    label = info.find(\"span\").text\n","                    value = info.find(\"span\").text\n","                    \n","                    item[label]=value\n","                    \n","                except AttributeError:\n","                  continue\n","\n","        except AttributeError:\n","            continue\n","\n","        # Bir tane veriyi mongoDB'ye ekler\n","        mycollectionTrendyol.insert_one(item)\n","\n","        # MongoDB'ye birer tane veri aktarmak istediğimiz için item içerisi silinir\n","        item.clear()"]}]}