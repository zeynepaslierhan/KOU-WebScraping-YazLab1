{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyN1G8vr6Uz1GOs/QtzPmmr7"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Giriş"],"metadata":{"id":"2b7kRrp-qWXh"}},{"cell_type":"markdown","source":["### Veritabanı Oluşturma"],"metadata":{"id":"ioO4pNXQ7ztz"}},{"cell_type":"markdown","source":["MongoDb de yapılan işlemler:\n","\n","1. Yeni bir Cluster oluşturuldu. İsmi: \"Cluster-WebScraping\"\n","2. Cluster-WebScraping için veritabanı erişim izni verilen iki kullanıcı oluşturuldu.\n","  \n","  * isim: zeyneperhan şifre: 20012022\n","  * isim: hazarkoc şifre:20012022 \n","\n","3. Cluster-WebScraping'e IP üzerinden otomatik bağlanmak için Ip adresi eklendi\n","\n","4. Cluster içerisine yeni veritabanı eklenip koleksiyon oluşturuldu."],"metadata":{"id":"m9m4-nCL5uwe"}},{"cell_type":"markdown","source":["### Pyhton ile Veritabanına Bağlanma"],"metadata":{"id":"BuAFvVgd8HB6"}},{"cell_type":"code","source":["# MongoDb işlemleri için gerekli kütüphaneler eklendi\n","import pymongo "],"metadata":{"id":"IsyqFcsB8ty1"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Cluster-WebScraping'e bağlanmak için :\n","\n","1. MongoDb Atlas veya MongoDb Compass'a göre seçim yapılır.\n","  \n","  * MongoDb Atlas'ı seçtiğimiz için MongoDB Drivers kısmı seçilir.\n","\n","2. Driver ve versiyonu seçilir.\n","  \n","  * Driver: Pyhton Versiyon: 3.4 ve sonrası\n","\n","  Burada verdiği linki direkt kopyalamamak gerekiyor!!! "],"metadata":{"id":"k9BfM5XU8vCX"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"fRIs4oX6vYtu"},"outputs":[],"source":["# Cluster-WebScraping için bağlantı sağlandı. (username: zeyneperhan password: 20012022)\n","myclient = pymongo.MongoClient(\"mongodb://zeynep:20012022@ac-akv12vk-shard-00-00.6erqfem.mongodb.net:27017,ac-akv12vk-shard-00-01.6erqfem.mongodb.net:27017,ac-akv12vk-shard-00-02.6erqfem.mongodb.net:27017/?ssl=true&replicaSet=atlas-8ffx15-shard-0&retryWrites=true&w=majority\") \n","\n","# Kullanacağımız veritabanı için erişim sağladık.\n","mydb = myclient[\"Bilgisayar\"]\n","\n","# Bilgisayar Veritabanındaki Amazon koleksiyonuna erişim sağladık\n","mycollectionAmazon= mydb[\"Amazon\"]"]},{"cell_type":"markdown","source":["# BeatifulSoup ile Amazon Web Scraping"],"metadata":{"id":"Y_fZdUc0omFu"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"q4Zk1RD5-FyT","executionInfo":{"status":"ok","timestamp":1666035848949,"user_tz":-180,"elapsed":472090,"user":{"displayName":"Zeynep Aslı Erhan","userId":"03313672524286903446"}},"outputId":"701e5a7b-5f8e-4689-d1d0-8d60fb5b4585"},"outputs":[{"output_type":"stream","name":"stdout","text":["-------------\n","Processing https://www.amazon.com.tr/s?k=Bilgisayar&page=1...\n","-------------\n","<Response [200]>\n","<Response [200]>\n","<Response [200]>\n","<Response [200]>\n","<Response [200]>\n","<Response [200]>\n","<Response [200]>\n","<Response [200]>\n","<Response [200]>\n","<Response [200]>\n","<Response [200]>\n","<Response [200]>\n","<Response [200]>\n","<Response [200]>\n","<Response [200]>\n","<Response [200]>\n","<Response [200]>\n","<Response [200]>\n","<Response [200]>\n","<Response [200]>\n","<Response [200]>\n","<Response [200]>\n","<Response [200]>\n","<Response [200]>\n","<Response [200]>\n","<Response [200]>\n","<Response [200]>\n","<Response [200]>\n","<Response [200]>\n","<Response [200]>\n","<Response [200]>\n","<Response [200]>\n","<Response [200]>\n","<Response [200]>\n","<Response [200]>\n","<Response [200]>\n","<Response [200]>\n","<Response [200]>\n","<Response [200]>\n","<Response [200]>\n","<Response [200]>\n","<Response [200]>\n","<Response [200]>\n","<Response [200]>\n","<Response [200]>\n","<Response [200]>\n","<Response [200]>\n","<Response [200]>\n","<Response [200]>\n","-------------\n","Processing https://www.amazon.com.tr/s?k=Bilgisayar&page=2...\n","-------------\n","<Response [200]>\n","<Response [200]>\n","<Response [200]>\n","<Response [200]>\n","<Response [200]>\n","<Response [200]>\n","<Response [200]>\n","<Response [200]>\n","<Response [200]>\n","<Response [200]>\n","<Response [200]>\n","<Response [200]>\n","<Response [200]>\n","<Response [200]>\n","<Response [200]>\n","<Response [200]>\n","<Response [200]>\n","<Response [200]>\n","<Response [200]>\n","<Response [200]>\n","<Response [200]>\n","<Response [200]>\n","<Response [200]>\n","<Response [200]>\n","<Response [200]>\n","<Response [200]>\n","<Response [200]>\n","<Response [200]>\n","<Response [200]>\n","<Response [200]>\n","<Response [200]>\n","<Response [200]>\n","<Response [200]>\n","<Response [200]>\n","<Response [200]>\n","<Response [200]>\n","<Response [200]>\n","<Response [200]>\n","<Response [200]>\n","<Response [200]>\n","<Response [200]>\n","<Response [200]>\n","<Response [200]>\n","<Response [200]>\n","<Response [200]>\n","<Response [200]>\n","<Response [200]>\n","<Response [200]>\n","<Response [200]>\n","-------------\n","Processing https://www.amazon.com.tr/s?k=Bilgisayar&page=3...\n","-------------\n","<Response [200]>\n","<Response [200]>\n","<Response [200]>\n","<Response [200]>\n","<Response [200]>\n","<Response [200]>\n","<Response [200]>\n","<Response [200]>\n","<Response [200]>\n","<Response [200]>\n","<Response [200]>\n","<Response [200]>\n","<Response [200]>\n","<Response [200]>\n","<Response [200]>\n","<Response [200]>\n","<Response [200]>\n","<Response [200]>\n","<Response [200]>\n","<Response [200]>\n","<Response [200]>\n","<Response [200]>\n","<Response [200]>\n","<Response [200]>\n","<Response [200]>\n","<Response [200]>\n","<Response [200]>\n","<Response [200]>\n","<Response [200]>\n","<Response [200]>\n","<Response [200]>\n","<Response [200]>\n","<Response [200]>\n","<Response [200]>\n","<Response [200]>\n","<Response [200]>\n","<Response [200]>\n","<Response [200]>\n","<Response [200]>\n","<Response [200]>\n","<Response [200]>\n","<Response [200]>\n","<Response [200]>\n","<Response [200]>\n","<Response [200]>\n","<Response [200]>\n","<Response [200]>\n","<Response [200]>\n","<Response [200]>\n"]}],"source":["import requests\n","from bs4 import BeautifulSoup\n","import pandas as pd\n","from time import sleep\n","\n","# Web Scraping yapılırken ilgili koleksiyona erişiliyor.\n","mycollectionAmazon= mydb[\"Amazon\"]\n","\n","# Web scraping ile veri aktarmadan önce koleksiyon içeriğini tamamen siliyoruz.\n","mycollectionAmazon.delete_many({}) \n","\n","headers = {\n","    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:94.0) Gecko/20100101 Firefox/94.0'}\n","\n","# Amazondaki filtrelemeyi sağlamak adına:\n","search_query = 'Bilgisayar'.replace(' ', '+')\n","\n","# Verileri çekeceğimiz sitenin ana url'si ile arama sorgusu ile beraber url'si\n","base_url = 'https://www.amazon.com.tr/s?k={0}'.format(search_query)\n","\n","#veriyi tutan dict\n","item = {}\n","\n","for i in range(1, 4):\n","    \n","    print(\"-------------\")\n","    print('Processing {0}...'.format(base_url + '&page={0}'.format(i)))\n","    print(\"-------------\")    \n","\n","    # İstenilen sayfanın verileri alınıyor:\n","    response = requests.get(base_url + '&page={0}'.format(i), headers=headers)\n","    # Veri alımı başarılıysa response 200 olarak görülmeli 503 ise request işlemi hatalıdır\n","    print(response)\n","\n","    # BeautifulSoup ile verilerin içeriğini alıp html.parser ile parçalayıyor. soup içerisinde tutuyor\n","    soup = BeautifulSoup(response.content, 'html.parser')\n","\n","    # Olduğumuz sayfadaki tüm ürünlerin bilgisi results içerisine aktarılır:\n","    results = soup.find_all('div',{'class': 'a-section a-spacing-base'})\n","\n","\n","    # Results içerisindeki ürün kadar bu for döngüsü döner.\n","    for result in results:\n","\n","        product_name = result.h2.text\n","        item[\"product_name\"] = product_name\n","\n","\n","        # Fiyat\n","\n","        if result.find(\"div\", {\"id\": \"apex_offerDisplay_desktop\"}) is not None:\n","          price=result.find(\"div\", {\"id\": \"corePrice_feature_div\"}).text.strip()\n","          \n","        else:\n","          price= None\n","        \n","        item[\"price\"] = price\n","\n","\n","        # Değerlendirme\n","\n","        if result.find('span', {'class': 'a-icon-alt'}) is not None:\n","            rating = result.find('span', {'class': 'a-icon-alt'}).text\n","            \n","        else:\n","          rating = None\n","        \n","        item[\"rating\"]= rating\n","\n","        try:\n","            product_url = 'https://amazon.com.tr' + result.h2.a['href']\n","            item[\"product_url\"]= product_url\n","\n","            # Ürün hakkında detaylı bilgi edinmek için:\n","\n","            product_response = requests.get(product_url, headers=headers)\n","            print(product_response)\n","\n","            product_soup = BeautifulSoup(product_response.content, 'html.parser')\n","            product_details = product_soup.find_all(\"div\",{\"class\":\"a-column a-span6\"})\n","\n","            for details in product_details:\n","              informations = details.find_all(\"tr\")\n","              \n","              for info in informations:\n","\n","                if info.find(\"th\",{\"class\":\"a-color-secondary a-size-base prodDetSectionEntry\"}) is not None:\n","\n","                    label = info.find(\"th\",{\"class\":\"a-color-secondary a-size-base prodDetSectionEntry\"}).text\n","                    value = info.find(\"td\",{\"class\":\"a-size-base prodDetAttrValue\"}).text\n","                    \n","                    # value başındaki boşluk silinir.\n","                    value= value.replace('\\n','', 1)\n","                    value= value.replace('                ‎','', 1)\n","\n","                    item[label]=value\n","\n","                else:\n","                  continue\n","\n","        except AttributeError:\n","            continue\n","\n","        # Bir tane veriyi mongoDB'ye ekler\n","        mycollectionAmazon.insert_one(item)\n","\n","        # MongoDB'ye birer tane veri aktarmak istediğimiz için item içerisi silinir\n","        item.clear()"]},{"cell_type":"markdown","source":["## Not:"],"metadata":{"id":"CnXM_JIW2SGn"}},{"cell_type":"markdown","source":["\n","❗ Çektiğiniz bilgileri \"print(xxx)\" ile ekrana bastırırsanız ne üzerinde çalıştığınızı anlamanız kolaylaşır.\n","---\n","***ÖRNEKLER:***\n","\n","1. Çalıştığınız url'den geri dönüş değerinin 200 veya 503 olduğunu inceleyerek başarılı veya başarısız istek olduğunu anlayabilirsiniz:\n","```\n","product_response = requests.get(product_url, headers=headers)\n","print(product_response)\n","```\n","\n","2. \".prettify()\" kodu çektiğiniz html bilgisini print ederken daha düzenli hale getirir. Aşağıdaki response içeriğindeki html bilgilerini \"print(soap)\" diye de inceleyebilirsiniz.\n","```\n","response = requests.get(base_url + '&page={0}'.format(i), headers=headers)\n","soup = BeautifulSoup(response.content, 'html.parser')\n","print(soup.prettify())\n","```\n","3. html içeriğinde bulmak istediğiniz kısmın doğru olup olmadığını anlamak adına da değişkenleri ekrana bastırabilirsiniz.\n","```\n","results = soup.find_all('div',{'class': 'a-section a-spacing-base'})\n","print(results)\n","```\n","<br/>\n","\n","❗ Bu işlemler web scraping konusunda hatta derin öğrenme gibi konularda bile hangi veri üzerinde işlemler yaptığınızı anlamak adına kolaylık sağlıyor. \n","\n","\n","\n","\n","\n"],"metadata":{"id":"PbEvxFpuF3eQ"}}]}